---
title: "Convolutional Neural Networks"
date: 2024-05-22T18:35:00+05:30
toc: false
category: ml-summer-school
author_profile: false
read_time: false
comments: false
share: false
related: false
header:
    image: /assets/images/blog-images/nyu-header.jpg
sidebar:
    nav: "ml-summer-school"
toc: true
toc_label: "Contents"
toc_icon: "book"
---
*NYU K12 STEM Education: Machine Learning (Day 7)*

![nyu-header]({{ site.url }}{{ site.baseurl }}/assets/images/blog-images/nyu-tandon-logo.png)

# Images in Computer
- Images are stored as arrays of quantized numbers in computers

## Gray Scale Images
- Gray scale image: 2D matrices with each entry specifying the intensity (brightness) of a pixel
- Pixel values range from 0 to 255, 0 being the darkest, 255 being the brightest

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/3x3-gray.png" 
alt="Figure 1: Grayscale Image">
<figcaption><em>Figure 1: Grayscale Image</em></figcaption>
</figure>

## Color Images:
- Color image: 3D array, 2 dimensions for space, 1 dimension for color
- Can be thought of as three 2D matrices stacked together into a cube, each 2D matrix specify the amount of each color: Red,Green, Blue value at each pixel

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/rgb_images.jpeg" 
alt="Figure 2: Color Image">
<figcaption><em>Figure 2: Color Image</em></figcaption>
</figure>

## Limits of Fully Connected Network
- In MNIST, we used a fully connected network, in which each neuron in the hidden layer is connected to all \\(28 \times 28 = 784\\) pixels
- Higher definition images often contain millions of pixels \\(\rightarrow \\) It is not practical to use fully connected network
- Fully connected network treat each individual pixel as a feature, it does not utilize the positional relationship between pixels

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/flattening.png" 
alt="Figure 3: Flattening an Image">
<figcaption><em>Figure 3: Flattening an Image</em></figcaption>
</figure>

# Convolution
An operation on an image(matrix) X with a kernel W

\\[
    Z = X \circledast W
\\]

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/conv-operation.png" 
alt="Figure 4: Convolution Operation">
<figcaption><em>Figure 4: Convolution Operation</em></figcaption>
</figure>

## Why Convolution?
- With convolution, each output pixel depends on only the neighboring pixels in the input
- This allows us to learn the positional relationship between pixels
- Use of different kernels allows us to detect features

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/conv_animation.gif" 
alt="Figure 5: Convolution Visualization">
<figcaption><em>Figure 5: Convolution Visualization</em></figcaption>
</figure>

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/conv2_animation.gif" 
alt="Figure 6: Convolution with Padding - Visualization">
<figcaption><em>Figure 6: Convolution with Padding - Visualization</em></figcaption>
</figure>

## Convolution for Multiple Channels
- A kernel for each channel. Could be same kernel, or different
- Perform a convolution for each of the channel, with the respective kernel
- Sum the results

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/multiple_convolutions.svg" 
alt="Figure 7: Convolution across channels">
<figcaption><em>Figure 7: Convolution across channels</em></figcaption>
</figure>

## Max-pooling
- Down-samples the inputs
- Provides translation invariance. Why? 
- Apply after activation!

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/max-pool.png" 
alt="Figure 8: Max-pooling">
<figcaption><em>Figure 8: Max-pooling</em></figcaption>
</figure>

# Data-augmentation
- Image classification is a difficult task
- We need more data!
- Labeling is expensive and time-consuming. 
- How can we create new images?

Examples: 
- Mirroring
<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/mirroring.png" 
alt="Figure 9: Mirroring">
<figcaption><em>Figure 9: Mirroring</em></figcaption>
</figure>

- Rotation and Translation
<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/rotate.png" 
alt="Figure 10: Rotation and Translation">
<figcaption><em>Figure 10: Rotation and Translation</em></figcaption>
</figure>

- Random Cropping
<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/random-crop.png" 
alt="Figure 11: Random Cropping">
<figcaption><em>Figure 11: Random Cropping</em></figcaption>
</figure>

- Color Shifting
<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/color-shift.png" 
alt="Figure 12: Color Shifting">
<figcaption><em>Figure 12: Color Shifting</em></figcaption>
</figure>

# Data Normalization
- Given the dataset \\((x_i, y_i) \\) for \\(i = 1, 2, \cdots, N\\)
- Mean: 

    \\[
        \bar{x} = \frac{1}{N} \sum^{N}_{i=1} x_i
    \\]
- Variance:
    
    \\[
        \sigma^{2} = \frac{1}{N} \sum^{N}_{i=1} (x_i - \bar{x})^{2}
    \\]
- Standard deviation:
    
    \\[
        \sigma = \sqrt{\sigma^2}
    \\]
- Normalization : Replace each \\(x_i\\) by \\(x_i' = \frac{x_i - \bar{x}}{\sigma} \\)
- The new dataset will have a mean of \\(0\\) and a variance of \\(1\\).

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/normalized-unnormalized.png" 
alt="Figure 13: Unnormalized Gradient Descent vs. Normalized Gradient Descent">
<figcaption><em>Figure 13: Unnormalized Gradient Descent vs. Normalized Gradient Descent</em></figcaption>
</figure>

# Batch Normalization
- We normalize the inputs to the network. Why not do that for the inputs to the hidden layers?
- Batch norm: normalize the inputs to a layer for each mini-batch.
- Apply before activation!

# Dropout
- Patented by Google
- Randomly disable neurons and their connections between each other.
- Reduce complex co-adaptive relationships between neurons.
- This is the same as using a neural network with the same amount of layers but less neurons per layer.
- The more neurons the more powerful the neural network is, and the more likely it is to overfit.
- This also means that the model can not rely on any single feature, therefore would need to spread out the weights.

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/dropout.png" 
alt="Figure 14: Dropout">
<figcaption><em>Figure 14: Dropout</em></figcaption>
</figure>

<!-- # Open Source Implementation
- If you are interested in building on top of a deep learning research paper it is a good idea to first go online and see if there is a nice open source implementation instead of starting from scratch.
- If you are in the field of computer vision, many networks would require an extensive hyperparameter search and multiple GPUs to train, this process might take weeks.
- People now open source their results along with the weights and these can be seen as a nice initialization to your application.

## Image Net Challenge -->

# Transfer Learning
- You can freeze the early layers and replace the last few layers to match your own application needs (e.g. different number of classes, different activation functions).
- Only train the replaced layers and use the weights of the early layers ”as-is”.
- This is similar to transferring the knowledge from one network to another, thus the name transfer learning.

<figure>
<img src="{{ site.url }}{{ site.baseurl }}/assets/images/ml-summer-school/day-7/transfer-learning.png" 
alt="Figure 15: Transfer Learning">
<figcaption><em>Figure 15: Transfer Learning</em></figcaption>
</figure>

---

# Demos
1. [Images in Computer](https://github.com/rugvedmhatre/NYU-ML-2024-Session-1/blob/main/day7/Images_In_Computer_Demo.ipynb)
2. [Kernels Example](https://github.com/rugvedmhatre/NYU-ML-2024-Session-1/blob/main/day7/Kernels_Demo.ipynb)
3. [CNN Example](https://github.com/rugvedmhatre/NYU-ML-2024-Session-1/blob/main/day7/cnn_example.ipynb)
4. [MNIST Classifier](https://github.com/rugvedmhatre/NYU-ML-2024-Session-1/blob/main/day7/demo_MNIST.ipynb)
5. [Cats and Dog](https://github.com/rugvedmhatre/NYU-ML-2024-Session-1/blob/main/day7/lab_transfer_learning_dog_cat.ipynb)

---

# References